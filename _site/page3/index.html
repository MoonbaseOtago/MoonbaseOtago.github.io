<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      VRoom! &middot; Superfast RISC-V
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/apple-touch-icon-144-precomposed.png">
  <link rel="shortcut icon" type="image/png"href="/talk/assets/moonbase_ico.png">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">
</head>


  <body class="theme-base-0b">

    <div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <a href="/"><img src="/public/images/moonbase_small.png"></a>
      <h1>
        <a href="/">
          VRoom!
        </a>
      </h1>
      <p class="lead">Very high end RISC-V implementation, cloud server class, out of order, super scalar, speculative, up to 8 IPC</p>
    </div>

    <nav class="sidebar-nav">
      <a class="sidebar-nav-item" href="/">Home</a>

      

      
      
        
          
        
      
        
          
            <a class="sidebar-nav-item" href="/about/">About</a>
          
        
      
        
      
        
          
            <a class="sidebar-nav-item" href="/contact/">Contact</a>
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
      

      <a class="sidebar-nav-item" href="https://MoonbaseOtago.github.io/index.html">Blog</a>
      <a class="sidebar-nav-item" href="https://MoonbaseOtago.github.io/talk/index.html">Architectural Talk</a>
      <a class="sidebar-nav-item" href="https://github.com/MoonbaseOtago/vroom">GitHub project</a>

    &copy; 2022 Moonbase Otago<br>All rights reserved.<br>
    <a class="sidebar-nav-item" href="https://hyde.getpoole.com/">Built with ...</a>
    </nav>
  </div>
</div>


    <div class="content container">
      <div class="posts">
  
  <div class="post">
    <h1 class="post-title">
      <a href="/2021/11/20/btc-part3/">
        VRoom! blog&#58; Branch Target Cache [BTC] (part 3) Managing a speculative subroutine call stack
      </a>
    </h1>

    <span class="post-date">20 Nov 2021</span>

    <p>This is the third of an occasional series of articles on the VRoom!/RVoom RISC-V 
CPU. This week a shorter update, we’re going to talk about how we can create speculative entries 
in the Branch Target Cache (BTC) call-return stack. A quick reminder of some of what we learned in the previous blog.</p>

<ul>
  <li>we decode large bundles of many instructions every clock</li>
  <li>we predict bundles not instructions</li>
  <li>we maintain a queue of pending uncommitted BTC predictions</li>
  <li>each entry overrides the ones after it and the main tables</li>
</ul>

<h3 id="introduction">Introduction</h3>

<p>Last time we talked about how we manage speculated branch target cache (BTC) entries, in short
we have a queue of speculated BTC updates in front of the normal BTC tables, those entries are
discarded or updated when a speculated branch is found to have been mispredicted, and retired into the
main tables when a corresponding branch (or rather bundle of instructions) is committed.</p>

<p><img src="/public/images/btc-queue.svg" alt="placeholder" title="Branch Target Cache example" /></p>

<h3 id="subroutine-call-stack">Subroutine call stack</h3>

<p>In addition to the standard BTC tables we also have a per-access mode call-return stack,
RISC-V defines for us the instructions that should be used to infer these (and which not to),
in the BTC we provide a 32-entry stack (smaller for M-mode) of the last 32 subroutine calls
so we can predict the return address when decoding ret instructions (if we get it wrong it’s
not the end of the world, it will be corrected when the ret instruction hits the branch ALU)</p>

<p><img src="public/images/stack.svg" width="300" /></p>

<p>Initially we thought we’d just tag branches with a pointer to the top-of stack, and wind it back when we got
a misprediction, then we found out a case which turned out to have a particularly heavy impact on performance:</p>

<pre>

	.....
	call	a
r1:	call	b
r2	....

a:	bnez	a0, 1f		&lt; branch mispredicted
	ret
1:	....

b:	....

</pre>

<p>essentially what happens here is that we speculatively fetch the following instruction stream:</p>

<pre>
	Instruction		call stack
	===========		==========
				

	call	a		r1 -
	bnez 	a0, 1f		r1 -	&lt; remembers TOS
	ret			-	&lt; everything from here on is 
	call	b		r2 -	  mispredicted
	....				

</pre>

<p>Sometime later the bnez is resolved in the branch ALU and discovered to have been mispredicted. But by that point
the return address ‘r1’ on the call stack has been popped and replaced with ‘r2’, even though we got the top of stack (TOS)
correct, its contents are wrong, and can’t be undone when we discover the misprediction.
This means that at some later time when we finally do return from subroutine ‘a’
the prediction will be to ‘r2’ rather than ‘r1’ - this in turn will result in another misprediction when that return
instruction hits the branch ALU, which is exactly what were were trying to avoid.</p>

<h3 id="solution">Solution</h3>

<p>Our solution is to take a similar approach to the one we took for the BTC tables and put a queue of prediction
history in front of the call/return stack, in this case it’s a queue of push and pop 
actions. Instead of being indexed by hashes of the PC/global history, it’s simply the TOS address that’s used instead.
Top of stack always returns the latest push that matches the current TOS (and the top of the actual backing stack otherwise).</p>

<p><img src="public/images/stack-queue.svg" width="400" /></p>

<p>Like BTC speculative queue mentioned in the previous blog entry this queue is managed by the same bundle tag we
attach to instructions in the commitQ - when a mispredicted branch instruction is discovered then the
return stack speculative queue is truncated removing entries that correspond to the discarded instruction bundles
and the TOS updated to the oldest retained entry.</p>

<p>Similarly when the last instruction in an instruction bundle is committed then related  call-return stack
speculative queue entries are
tagged ‘committed’, and then written back in order into the call-return stack.</p>

<h3 id="to-recap">To Recap</h3>
<p>The important ideas here:</p>

<ul>
  <li>we have call-return stacks to predict the address of return instructions</li>
  <li>we maintain a queue of speculative push/pop transitions</li>
  <li>each entry overrides the ones after it and the main tables</li>
  <li>the queue is flushed on a misprediction</li>
  <li>committed data is pushed into the main tables</li>
</ul>

<p>Next time: How our main pipe works - an overview</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/2021/11/14/btc-part2/">
        VRoom! blog&#58; Branch Target Cache [BTC] (part 2) Living in a Speculative World
      </a>
    </h1>

    <span class="post-date">14 Nov 2021</span>

    <p>This is the second of an occasional series of articles on the VRoom!/RVoom RISC-V 
CPU. This week we’re going to talk about how we can create speculative entries 
in the Branch Target Cache (BTC). A quick reminder of some of what we learned in the previous blog.</p>

<ul>
  <li>we decode large bundles of many instructions every clock</li>
  <li>we predict bundles not instructions</li>
</ul>

<h3 id="system-architecture">System Architecture</h3>

<p>Let’s have a look at an overview of our system architecture:</p>

<p><img src="/talk/assets/overview.svg" alt="placeholder" title="System Architecture" /></p>

<p>Instructions are fetched from the instruction cache (I$1), decoded, renamed to commit registers and entered
into the commitQ. Once in the commitQ instructions can be executed in any order and even after they are
executed they can be discarded by a trap or a preceding mispredicted branch.</p>

<p>At the end of the commitQ are committed instructions, when they and all instructions before them are done, all
branches are correctly predicted, there are no pending traps, then the CPU will retire up to the last 8 
committed instructions per clock.</p>

<h3 id="btc-operations">BTC Operations</h3>

<p>Our BTC contains tables that are accessed using hashes constructed from the program counter (PC) and a
global history. On a traditional system the BTC tables and global history would be updated on every 
clock, In VROOM! we can have many instructions outstanding, often they are speculative instructions
that may never be committed - when a branch instruction is processed by the branch ALU and is discovered to have been
speculated incorrectly it can trigger
the discard of subsequent speculative instructions (including other branch instructions), branch instructions can
also be processed out of order.</p>

<p>Processing branch instructions is important, we want to use branch mis-predictions to update the BTC tables - if
we assumed that a branch would be taken and it wasn’t we need to back out and change the value that we had 
previously set them too.</p>

<p>A simple solution (and the one that we originally tried) was to wait until the commit stage of the CPU
and then only use instructions that have been committed (and branches that have been resolved) to update the BTC tables.
It works, but it’s very slow to update (remember that a big version of our CPU can have ~150 instructions in flight at
once). Consider something like this:</p>

<pre>
clear:
1:	std	x0, (a0)
	add	a0, a0, 8
	add	a1, a1, -1
	bnez	a1, 1b
	ret
</pre>

<p>The core of this is a single decode-bundle that always loops and contains 4 instruction in its core.
The CPU may push 150/4 = 30+ bundles, 30 times around the loop, before we can start updating the
BTC - this is particularly a problem with global history predictors which to be useful really to be updated 
on every prediction.</p>

<h3 id="a-better-solution">A better solution</h3>

<p>Let’s look at how our BTC works:</p>

<p><img src="/public/images/btc.svg" alt="placeholder" title="Branch Target Cache example" /></p>

<p>The PC and the global history (a bit vector) are hashed (just some xors and bit swapping) into indexes into the 3
BTC tables, they’re used to look up the 3 tables. The combined output is used to choose whether the bimodal or
global history predictor is best for a particular bundle.</p>

<p>Our solution to the above problems is to create a ‘pending prediction’ queue in front of the normal BTC tables. Each
entry contains the information about a bundle prediction. Including the PC used for it and the global history at the
point that it was created.
Newer predictions are performed by looking into the queue from
most recent to oldest for each of the 3 hashes (individually and independently) comparing them with the hashes of the
PC and global history generated in each entry, if no match is found then the value from the main tables is used.</p>

<p><img src="/public/images/btc-queue.svg" alt="placeholder" title="Branch Target Cache example" /></p>

<p>The per-bundle BTC pending prediction queue acts similarly to the main per-instruction commitQ - in this case
each instruction in the commitQ carries a reference to the decode-bundle it came from.</p>

<h3 id="actions">Actions</h3>

<p>If a branch instruction in the commitQ is discovered to be mispredicted
all the instructions following it are discarded. At the same time entries in the BTC
prediction queue that are newer than the bundle corresponding to  the mispredicted instruction are also discarded, and the
prediction queue entry that does correspond to the mispredicted branch has its data updated. Finally that prediction queue’s
copy of the global history along with the new branch information is used to reload the global history
vector used for the next BTC prediction.</p>

<p>Finally each BTC pending queue entry has a ‘committed’ bit - it gets set when all the instructions in the corresponding
bundle hit the commit state in the commitQ, that means none of them will be mispredicted, or already have been.
On every clock if the oldest entry in the BTC pending queue has its committed bit set then its data is copied back into the main BTC tables.</p>

<h3 id="to-recap">To Recap</h3>
<p>The important ideas here:</p>

<ul>
  <li>we maintain a queue of pending uncommitted BTC predictions</li>
  <li>each entry overrides the ones after it and the main tables</li>
  <li>the queue is flushed and the top entry updated on a misprediction</li>
  <li>committed data is pushed into the main tables</li>
</ul>

<p>Next time: BTC (Part 3) Predicting Subroutine Returns</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/2021/11/06/introducing-vroom/">
        Blog&#58; Introducing Vroom!
      </a>
    </h1>

    <span class="post-date">06 Nov 2021</span>

    <p><img src="/talk/assets/chip.png" alt="placeholder" title="Branch Target Cache example" /></p>

<h3 id="executive-summary">Executive Summary</h3>

<ul>
  <li>Very high end RISC-V implementation – goal cloud server class</li>
  <li>Out of order, super scalar, speculative</li>
  <li>RV64-IMAFDCHB(V)</li>
  <li>Up to 8 IPC (instructions per clock) peak, goal ~4 average on ALU heavy work</li>
  <li>2-way simultaneous multithreading capable</li>
  <li>Multi-core</li>
  <li>Early (low) dhrystone numbers: ~3.6 DMips/MHz - still a work in progress. Goal ~4-5</li>
  <li>Currently boots Linux on an AWS-FPGA instance</li>
  <li>GPL3 – dual licensing possible</li>
</ul>

<h3 id="downloads">Downloads</h3>

<p>VRoom! is hosted with GitHub. Head to the <a href="https://github.com/MoonbaseOtago/vroom">GitHub repository</a> for downloads.</p>

<h3 id="licensing">Licensing</h3>

<p>VRoom! is currently licensed GPL3. We recognize that for many reasons one cannot practically build a large GPL3d chip 
design - VRoom! is also available to be commercial licensed.</p>


  </div>
  
</div>

<div class="pagination">
  
    <span class="pagination-item older">Older</span>
  
  
    
      <a class="pagination-item newer" href="/../page2">Newer</a>
    
  
</div>

    </div>

  </body>
</html>
